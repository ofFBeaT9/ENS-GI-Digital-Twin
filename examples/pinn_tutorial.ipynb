{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks (PINN) for Parameter Estimation\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "This tutorial covers:\n",
    "1. **What is a PINN?** - Combining data with physics\n",
    "2. **Training a PINN** - Creating synthetic datasets\n",
    "3. **Parameter estimation** - Solving the inverse problem\n",
    "4. **Uncertainty quantification** - Bootstrap confidence intervals\n",
    "5. **Model validation** - Testing accuracy\n",
    "6. **Comparison with Bayesian methods**\n",
    "\n",
    "## What is a Physics-Informed Neural Network?\n",
    "\n",
    "Traditional neural networks learn from data alone:\n",
    "```\n",
    "NN(data) → output\n",
    "```\n",
    "\n",
    "**PINNs** also enforce physical laws (ODEs, PDEs):\n",
    "```\n",
    "Total Loss = Data Loss + Physics Loss\n",
    "           = ||NN(data) - measurements||² + ||dV/dt - f(V, params)||²\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- More accurate with limited data\n",
    "- Physically consistent predictions\n",
    "- Better generalization\n",
    "- Can solve inverse problems (data → hidden parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from ens_gi_core import ENSGIDigitalTwin\n",
    "\n",
    "try:\n",
    "    from ens_gi_pinn import PINNEstimator, PINNConfig\n",
    "    import tensorflow as tf\n",
    "    PINN_AVAILABLE = True\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\nexcept ImportError as e:\n",
    "    PINN_AVAILABLE = False\n",
    "    print(f\"PINN not available: {e}\")\n",
    "    print(\"Install with: pip install tensorflow\")\n",
    "\n",
    "if PINN_AVAILABLE:\n",
    "    print(\"PINN framework ready!\")\n",
    "else:\n",
    "    print(\"This tutorial requires TensorFlow. Please install and restart.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Inverse Problem\n",
    "\n",
    "**Forward Problem** (easy): Given parameters → predict observations\n",
    "```python\n",
    "twin.set_parameters(g_Na=120, g_K=36)\n",
    "result = twin.run()\n",
    "# We get voltage traces\n",
    "```\n",
    "\n",
    "**Inverse Problem** (hard): Given observations → estimate parameters\n",
    "```python\n",
    "# We have voltage traces from a patient\n",
    "# What are g_Na and g_K?\n",
    "pinn.estimate_parameters(voltage_data) → {g_Na: 85 ± 5, g_K: 42 ± 3}\n",
    "```\n",
    "\n",
    "This is what PINNs solve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PINN_AVAILABLE:\n",
    "    raise ImportError(\"TensorFlow required for this tutorial\")\n",
    "\n",
    "# Create ground truth patient with KNOWN parameters\n",
    "print(\"Creating synthetic patient...\")\n",
    "true_g_Na = 100.0  # This is what we want to recover\n",
    "true_g_K = 40.0\n",
    "true_omega = 0.01\n",
    "\n",
    "patient = ENSGIDigitalTwin(n_segments=10)\n",
    "\n",
    "# Set known parameters\n",
    "for neuron in patient.network.neurons:\n",
    "    neuron.params.g_Na = true_g_Na\n",
    "    neuron.params.g_K = true_g_K\n",
    "patient.network.icc.omega = true_omega\n",
    "\n",
    "# Generate \"clinical\" data\n",
    "print(\"Simulating clinical measurements...\")\n",
    "result = patient.run(1500, dt=0.1, I_stim={4: 10.0}, verbose=False)\n",
    "\n",
    "print(f\"\\nGenerated data:\")\n",
    "print(f\"  Voltage traces: {result['voltages'].shape}\")\n",
    "print(f\"  Force traces: {result['forces'].shape}\")\n",
    "print(f\"  Calcium traces: {result['calcium'].shape}\")\n",
    "\n",
    "print(f\"\\nTrue parameters (hidden from PINN):\")\n",
    "print(f\"  g_Na = {true_g_Na}\")\n",
    "print(f\"  g_K = {true_g_K}\")\n",
    "print(f\"  omega = {true_omega}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Configure and Create PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure PINN architecture\n",
    "config = PINNConfig(\n",
    "    architecture='resnet',  # ResNet better for deep networks\n",
    "    hidden_dims=[128, 64, 32],  # 3 hidden layers\n",
    "    activation='tanh',  # Smooth activation\n",
    "    learning_rate=0.001,  # Adam learning rate\n",
    "    lambda_data=1.0,  # Data loss weight\n",
    "    lambda_physics=0.1,  # Physics loss weight (10%)\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Create PINN estimator\n",
    "twin_for_pinn = ENSGIDigitalTwin(n_segments=10)\n",
    "pinn = PINNEstimator(\n",
    "    digital_twin=twin_for_pinn,\n",
    "    config=config,\n",
    "    parameter_names=['g_Na', 'g_K', 'omega']\n",
    ")\n",
    "\n",
    "print(\"PINN Model Summary:\")\n",
    "print(f\"  Architecture: {config.architecture}\")\n",
    "print(f\"  Parameters to estimate: {pinn.parameter_names}\")\n",
    "print(f\"  Total model parameters: {pinn.model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Generate Training Dataset\n",
    "\n",
    "PINN needs training data with known parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic training dataset\n",
    "print(\"Generating training dataset (this may take 1-2 minutes)...\")\n",
    "dataset = pinn.generate_synthetic_dataset(n_samples=500)\n",
    "\n",
    "print(f\"\\nDataset created:\")\n",
    "print(f\"  Features shape: {dataset['features'].shape}\")\n",
    "print(f\"  Parameters shape: {dataset['parameters'].shape}\")\n",
    "print(f\"  Number of samples: {len(dataset['parameters'])}\")\n",
    "\n",
    "# Show parameter distribution in training set\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "param_names = ['g_Na', 'g_K', 'omega']\n",
    "for idx, (ax, name) in enumerate(zip(axes, param_names)):\n",
    "    ax.hist(dataset['parameters'][:, idx], bins=30, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel(name, fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_title(f'{name} Distribution in Training Set', fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train the PINN\n",
    "\n",
    "Training minimizes: `Total Loss = Data Loss + Physics Loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PINN\n",
    "print(\"Training PINN (this will take 2-3 minutes)...\\n\")\n",
    "history = pinn.train(\n",
    "    features=dataset['features'],\n",
    "    parameters=dataset['parameters'],\n",
    "    epochs=1000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Total loss\n",
    "axes[0].plot(history['loss'], label='Training', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Total Loss')\n",
    "axes[0].set_title('Training Progress', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Data loss\n",
    "axes[1].plot(history['data_loss'], linewidth=2, color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Data Loss')\n",
    "axes[1].set_title('Data Fitting', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "# Physics loss\n",
    "axes[2].plot(history['physics_loss'], linewidth=2, color='red')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Physics Loss')\n",
    "axes[2].set_title('Physics Constraint', fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal training loss: {history['loss'][-1]:.6f}\")\n",
    "print(f\"Final validation loss: {history['val_loss'][-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Estimate Patient Parameters\n",
    "\n",
    "Now use the trained PINN to estimate parameters from \"clinical\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate parameters with uncertainty quantification\n",
    "print(\"Estimating parameters with bootstrap uncertainty...\")\n",
    "estimates = pinn.estimate_parameters(\n",
    "    voltages=result['voltages'],\n",
    "    forces=result['forces'],\n",
    "    calcium=result['calcium'],\n",
    "    n_bootstrap=50  # 50 bootstrap samples\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PINN PARAMETER ESTIMATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Parameter':<12} {'True Value':<15} {'Estimated':<20} {'Error':<10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "true_values = {'g_Na': true_g_Na, 'g_K': true_g_K, 'omega': true_omega}\n",
    "\n",
    "for param in ['g_Na', 'g_K', 'omega']:\n",
    "    if param in estimates:\n",
    "        est = estimates[param]\n",
    "        true_val = true_values[param]\n",
    "        error = abs(est['mean'] - true_val) / true_val * 100\n",
    "        \n",
    "        print(f\"{param:<12} {true_val:<15.4f} \"\n",
    "              f\"{est['mean']:.4f} ± {est['std']:.4f}  \"\n",
    "              f\"{error:>6.1f}%\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Success criteria\n",
    "avg_error = np.mean([abs(estimates[p]['mean'] - true_values[p]) / true_values[p] * 100 \n",
    "                     for p in ['g_Na', 'g_K', 'omega'] if p in estimates])\n",
    "\n",
    "print(f\"\\nAverage Error: {avg_error:.2f}%\")\n",
    "if avg_error < 10:\n",
    "    print(\"SUCCESS: Error < 10% (target achieved!)\")\n",
    "elif avg_error < 20:\n",
    "    print(\"GOOD: Error < 20% (acceptable for clinical use)\")\n",
    "else:\n",
    "    print(\"NEEDS IMPROVEMENT: Error > 20%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Visualize Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameter estimates with confidence intervals\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, (param, ax) in enumerate(zip(['g_Na', 'g_K', 'omega'], axes)):\n",
    "    if param in estimates:\n",
    "        est = estimates[param]\n",
    "        true_val = true_values[param]\n",
    "        \n",
    "        # Plot estimate with error bars\n",
    "        ax.errorbar([0], [est['mean']], yerr=[2*est['std']], \n",
    "                   fmt='o', markersize=12, capsize=10, capthick=2,\n",
    "                   label='PINN Estimate', color='blue')\n",
    "        \n",
    "        # Plot true value\n",
    "        ax.axhline(y=true_val, color='red', linestyle='--', linewidth=2,\n",
    "                  label='True Value')\n",
    "        \n",
    "        # Shaded confidence region\n",
    "        ax.axhspan(est['mean'] - 2*est['std'], \n",
    "                  est['mean'] + 2*est['std'],\n",
    "                  alpha=0.2, color='blue', label='95% CI')\n",
    "        \n",
    "        ax.set_ylabel(param, fontsize=14, fontweight='bold')\n",
    "        ax.set_title(f\"{param} Estimation\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlim(-0.5, 0.5)\n",
    "        ax.set_xticks([])\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Test on IBS Profiles\n",
    "\n",
    "Can PINN distinguish between healthy and IBS patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on different IBS profiles\n",
    "profiles_to_test = ['healthy', 'ibs_c', 'ibs_d']\n",
    "profile_results = {}\n",
    "\n",
    "print(\"Testing PINN on different IBS profiles...\\n\")\n",
    "\n",
    "for profile in profiles_to_test:\n",
    "    print(f\"Testing {profile.upper()}...\")\n",
    "    \n",
    "    # Create patient with profile\n",
    "    test_twin = ENSGIDigitalTwin(n_segments=10)\n",
    "    test_twin.apply_profile(profile)\n",
    "    test_result = test_twin.run(1500, dt=0.1, verbose=False)\n",
    "    \n",
    "    # Estimate parameters\n",
    "    test_estimates = pinn.estimate_parameters(\n",
    "        voltages=test_result['voltages'],\n",
    "        forces=test_result['forces'],\n",
    "        calcium=test_result['calcium'],\n",
    "        n_bootstrap=20\n",
    "    )\n",
    "    \n",
    "    profile_results[profile] = test_estimates\n",
    "    \n",
    "    if 'g_Na' in test_estimates:\n",
    "        print(f\"  g_Na: {test_estimates['g_Na']['mean']:.2f} ± {test_estimates['g_Na']['std']:.2f}\")\n",
    "\n",
    "# Compare profiles\n",
    "print(\"\\nProfile Comparison:\")\n",
    "print(f\"  Healthy g_Na: {profile_results['healthy']['g_Na']['mean']:.2f}\")\n",
    "print(f\"  IBS-C g_Na: {profile_results['ibs_c']['g_Na']['mean']:.2f} (should be lower)\")\n",
    "print(f\"  IBS-D g_Na: {profile_results['ibs_d']['g_Na']['mean']:.2f} (should be higher)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Save and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained PINN\n",
    "pinn.save('trained_pinn_model')\n",
    "print(\"Model saved to: trained_pinn_model/\")\n",
    "\n",
    "# Load model\n",
    "loaded_pinn = PINNEstimator.load('trained_pinn_model')\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Verify it works\n",
    "test_estimates = loaded_pinn.estimate_parameters(\n",
    "    voltages=result['voltages'],\n",
    "    forces=result['forces'],\n",
    "    calcium=result['calcium']\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded model g_Na estimate: {test_estimates['g_Na']['mean']:.2f}\")\n",
    "print(f\"Original model g_Na estimate: {estimates['g_Na']['mean']:.2f}\")\n",
    "print(\"Models match!\" if abs(test_estimates['g_Na']['mean'] - estimates['g_Na']['mean']) < 0.1 else \"Models differ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated:\n",
    "\n",
    "1. ✅ **PINN concept** - Combining data with physics\n",
    "2. ✅ **Training** - Generated 500 synthetic samples\n",
    "3. ✅ **Parameter estimation** - Solved inverse problem\n",
    "4. ✅ **Uncertainty** - Bootstrap confidence intervals\n",
    "5. ✅ **Validation** - Tested on multiple IBS profiles\n",
    "6. ✅ **Persistence** - Save/load trained models\n",
    "\n",
    "### Key Advantages of PINN:\n",
    "\n",
    "- **Fast**: ~1-2 minutes for parameter estimation\n",
    "- **Accurate**: Typically <10% error with good data\n",
    "- **Uncertainty**: Bootstrap provides confidence intervals\n",
    "- **Scalable**: Can handle high-dimensional parameter spaces\n",
    "- **Physically consistent**: Enforces ODE constraints\n",
    "\n",
    "### When to Use PINN vs Bayesian:\n",
    "\n",
    "**Use PINN when:**\n",
    "- You need fast results (<5 minutes)\n",
    "- You have moderate amounts of data\n",
    "- Point estimates + bootstrap CI are sufficient\n",
    "- Multiple parameters to estimate (>5)\n",
    "\n",
    "**Use Bayesian when:**\n",
    "- You need full posterior distributions\n",
    "- Clinical decisions require rigorous uncertainty\n",
    "- Small dataset but strong priors\n",
    "- Regulatory approval requires UQ\n",
    "\n",
    "**Best approach:** Use PINN first, then refine with Bayesian!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try the Bayesian tutorial (`bayesian_tutorial.ipynb`)\n",
    "- Explore clinical workflow (`clinical_workflow.ipynb`)\n",
    "- Test on real patient data\n",
    "- Publish results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
