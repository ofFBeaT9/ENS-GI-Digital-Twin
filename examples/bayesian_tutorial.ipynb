{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference for Parameter Estimation with Uncertainty\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "This tutorial covers:\n",
    "1. **What is Bayesian inference?** - Probabilistic parameter estimation\n",
    "2. **Prior distributions** - Encoding domain knowledge\n",
    "3. **MCMC sampling** - Exploring posterior distributions\n",
    "4. **Convergence diagnostics** - R-hat, effective sample size\n",
    "5. **Credible intervals** - 95% uncertainty bounds\n",
    "6. **Comparison with PINN** - When to use each method\n",
    "\n",
    "## Bayes' Theorem\n",
    "\n",
    "$$P(\\theta|D) = \\frac{P(D|\\theta) \\times P(\\theta)}{P(D)}$$\n",
    "\n",
    "Where:\n",
    "- **P(θ|D)** = Posterior (what we want) - parameter distributions given data\n",
    "- **P(D|θ)** = Likelihood - how well parameters explain data\n",
    "- **P(θ)** = Prior - what we know before seeing data\n",
    "- **P(D)** = Evidence (normalizing constant)\n",
    "\n",
    "**Key Insight:** We get full probability distributions, not just point estimates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from ens_gi_core import ENSGIDigitalTwin\n",
    "\n",
    "try:\n",
    "    from ens_gi_bayesian import BayesianEstimator, BayesianConfig, get_default_priors\n",
    "    import pymc3 as pm\n",
    "    import arviz as az\n",
    "    BAYESIAN_AVAILABLE = True\n",
    "    print(f\"PyMC3 version: {pm.__version__}\")\n",
    "    print(f\"ArviZ version: {az.__version__}\")\n",
    "except ImportError as e:\n",
    "    BAYESIAN_AVAILABLE = False\n",
    "    print(f\"Bayesian framework not available: {e}\")\n",
    "    print(\"Install with: pip install pymc3 arviz\")\n",
    "\n",
    "if BAYESIAN_AVAILABLE:\n",
    "    print(\"\\nBayesian framework ready!\")\n",
    "else:\n",
    "    print(\"\\nThis tutorial requires PyMC3 and ArviZ. Please install and restart.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Prior Distributions\n",
    "\n",
    "Priors encode what we know about parameters *before* seeing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not BAYESIAN_AVAILABLE:\n",
    "    raise ImportError(\"PyMC3 required for this tutorial\")\n",
    "\n",
    "# Get default priors\n",
    "priors = get_default_priors()\n",
    "\n",
    "print(\"Default Prior Distributions:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Parameter':<15} {'Distribution':<15} {'Mean':<10} {'Bounds'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for prior in priors[:6]:  # Show first 6\n",
    "    dist_str = f\"{prior.distribution}\"\n",
    "    mean_str = str(prior.params.get('mu', prior.params.get('lower', 'N/A')))\n",
    "    bounds_str = f\"[{prior.bounds[0]:.1f}, {prior.bounds[1]:.1f}]\" if prior.bounds else \"unbounded\"\n",
    "    print(f\"{prior.name:<15} {dist_str:<15} {mean_str:<10} {bounds_str}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPrior Interpretation:\")\n",
    "print(\"  • g_Na ~ Normal(120, 20): We expect ~120 mS/cm² ± 20\")\n",
    "print(\"  • Bounds prevent unphysical values (e.g., negative conductances)\")\n",
    "print(\"  • Weakly informative: Allow data to dominate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Create Synthetic Patient Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create patient with known parameters (ground truth)\n",
    "print(\"Creating synthetic patient...\")\n",
    "true_g_Na = 105.0\n",
    "true_g_K = 38.0\n",
    "\n",
    "patient = ENSGIDigitalTwin(n_segments=8)\n",
    "for neuron in patient.network.neurons:\n",
    "    neuron.params.g_Na = true_g_Na\n",
    "    neuron.params.g_K = true_g_K\n",
    "\n",
    "# Generate data\n",
    "result = patient.run(1000, dt=0.1, I_stim={3: 10.0}, verbose=False)\n",
    "\n",
    "# Add realistic measurement noise\n",
    "noise_level = 2.0  # mV\n",
    "noisy_voltages = result['voltages'] + np.random.normal(0, noise_level, result['voltages'].shape)\n",
    "\n",
    "print(f\"\\nData generated:\")\n",
    "print(f\"  Clean voltage: {result['voltages'].shape}\")\n",
    "print(f\"  Noisy voltage: {noisy_voltages.shape}\")\n",
    "print(f\"  Noise level: {noise_level} mV\")\n",
    "print(f\"\\nTrue parameters (what we want to recover):\")\n",
    "print(f\"  g_Na = {true_g_Na}\")\n",
    "print(f\"  g_K = {true_g_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Configure Bayesian Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MCMC sampling\n",
    "config = BayesianConfig(\n",
    "    n_chains=4,  # Run 4 parallel chains\n",
    "    n_draws=1000,  # 1000 samples per chain\n",
    "    n_tune=500,  # 500 tuning steps (burn-in)\n",
    "    sampler='NUTS',  # No-U-Turn Sampler (best for continuous params)\n",
    "    target_accept=0.95,  # High acceptance rate for accuracy\n",
    "    progressbar=True\n",
    ")\n",
    "\n",
    "# Create estimator\n",
    "twin_for_bayes = ENSGIDigitalTwin(n_segments=8)\n",
    "bayes = BayesianEstimator(\n",
    "    digital_twin=twin_for_bayes,\n",
    "    config=config,\n",
    "    parameter_names=['g_Na', 'g_K']\n",
    ")\n",
    "\n",
    "print(\"Bayesian Estimator configured:\")\n",
    "print(f\"  Sampler: {config.sampler}\")\n",
    "print(f\"  Chains: {config.n_chains}\")\n",
    "print(f\"  Samples per chain: {config.n_draws}\")\n",
    "print(f\"  Total samples: {config.n_chains * config.n_draws}\")\n",
    "print(f\"  Parameters: {bayes.parameter_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Run MCMC Sampling\n",
    "\n",
    "This explores the posterior distribution using Markov Chain Monte Carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MCMC (this may take 3-5 minutes)\n",
    "print(\"Running MCMC sampling...\")\n",
    "print(\"This will take 3-5 minutes. Please be patient!\\n\")\n",
    "\n",
    "try:\n",
    "    trace = bayes.estimate_parameters(\n",
    "        observed_voltages=noisy_voltages,\n",
    "        parameter_names=['g_Na', 'g_K']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nMCMC sampling complete!\")\n",
    "    print(f\"Trace contains {len(trace.posterior.chain) * len(trace.posterior.draw)} samples\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nMCMC failed: {e}\")\n",
    "    print(\"This is OK in test environments. Continuing with demo...\")\n",
    "    trace = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Analyze Posterior Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trace is not None:\n",
    "    # Get summary statistics\n",
    "    summary = bayes.summarize_posterior(trace)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BAYESIAN POSTERIOR SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Parameter':<12} {'True':<10} {'Mean':<12} {'SD':<10} {'95% CI':<25} {'R-hat'}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    true_vals = {'g_Na': true_g_Na, 'g_K': true_g_K}\n",
    "    \n",
    "    for param in ['g_Na', 'g_K']:\n",
    "        if param in summary:\n",
    "            s = summary[param]\n",
    "            true = true_vals[param]\n",
    "            ci_str = f\"[{s['ci_lower']:.2f}, {s['ci_upper']:.2f}]\"\n",
    "            covered = \"✓\" if s['ci_lower'] <= true <= s['ci_upper'] else \"✗\"\n",
    "            \n",
    "            print(f\"{param:<12} {true:<10.2f} {s['mean']:<12.2f} {s['std']:<10.2f} \"\n",
    "                  f\"{ci_str:<25} {s.get('rhat', 1.0):.3f} {covered}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  • Mean: Expected value (point estimate)\")\n",
    "    print(\"  • SD: Uncertainty in estimate\")\n",
    "    print(\"  • 95% CI: We're 95% confident true value is in this range\")\n",
    "    print(\"  • R-hat < 1.01: Chains converged (good!)\")\n",
    "    print(\"  • ✓: True value within 95% CI (validation success!)\")\n",
    "else:\n",
    "    print(\"Trace not available (MCMC skipped).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Visualize Posterior Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trace is not None:\n",
    "    # Trace plot (shows MCMC chains)\n",
    "    print(\"Generating trace plot...\")\n",
    "    az.plot_trace(trace, compact=True, figsize=(12, 6))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTrace Plot Interpretation:\")\n",
    "    print(\"  Left: Distributions (should be smooth, unimodal)\")\n",
    "    print(\"  Right: MCMC chains (should be 'hairy caterpillars' - good mixing)\")\n",
    "    print(\"  All chains should overlap (convergence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trace is not None:\n",
    "    # Posterior density plot\n",
    "    print(\"Generating posterior density plot...\")\n",
    "    az.plot_posterior(trace, figsize=(12, 4), hdi_prob=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nPosterior Plot Shows:\")\n",
    "    print(\"  • Peak: Most likely value\")\n",
    "    print(\"  • Width: Uncertainty\")\n",
    "    print(\"  • Shaded region: 95% highest density interval (HDI)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Convergence Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trace is not None:\n",
    "    # Check convergence\n",
    "    print(\"Convergence Diagnostics:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # R-hat (should be < 1.01)\n",
    "    rhat = az.rhat(trace)\n",
    "    print(\"\\nR-hat (Gelman-Rubin):\")\n",
    "    for var in rhat.data_vars:\n",
    "        val = float(rhat[var].values)\n",
    "        status = \"✓ Good\" if val < 1.01 else \"✗ Poor\" if val < 1.1 else \"✗✗ Bad\"\n",
    "        print(f\"  {var}: {val:.4f} {status}\")\n",
    "    \n",
    "    # Effective sample size\n",
    "    ess = az.ess(trace)\n",
    "    print(\"\\nEffective Sample Size (ESS):\")\n",
    "    for var in ess.data_vars:\n",
    "        val = float(ess[var].values)\n",
    "        total = config.n_chains * config.n_draws\n",
    "        efficiency = val / total * 100\n",
    "        status = \"✓ Good\" if efficiency > 10 else \"~ OK\" if efficiency > 5 else \"✗ Poor\"\n",
    "        print(f\"  {var}: {val:.0f} / {total} ({efficiency:.1f}%) {status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Interpretation:\")\n",
    "    print(\"  • R-hat < 1.01: Chains have converged\")\n",
    "    print(\"  • ESS > 10%: Sufficient independent samples\")\n",
    "else:\n",
    "    print(\"Convergence diagnostics require trace (MCMC skipped).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Compare with PINN Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate PINN estimates (normally would run actual PINN)\n",
    "print(\"Comparing Bayesian vs PINN:\\n\")\n",
    "\n",
    "# Mock PINN estimates\n",
    "pinn_estimates = {\n",
    "    'g_Na': true_g_Na + np.random.normal(0, 3),\n",
    "    'g_K': true_g_K + np.random.normal(0, 2)\n",
    "}\n",
    "pinn_uncertainties = {'g_Na': 5.0, 'g_K': 3.0}\n",
    "\n",
    "if trace is not None:\n",
    "    comparison = bayes.compare_with_pinn(\n",
    "        pinn_estimates=pinn_estimates,\n",
    "        pinn_uncertainties=pinn_uncertainties,\n",
    "        trace=trace\n",
    "    )\n",
    "    \n",
    "    print(f\"{'Parameter':<12} {'PINN':<15} {'Bayesian':<15} {'Agreement'}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for param in ['g_Na', 'g_K']:\n",
    "        if param in comparison:\n",
    "            comp = comparison[param]\n",
    "            bayes_str = f\"{summary[param]['mean']:.2f} ± {summary[param]['std']:.2f}\"\n",
    "            pinn_str = f\"{pinn_estimates[param]:.2f} ± {pinn_uncertainties[param]:.2f}\"\n",
    "            agree = comp['agreement']\n",
    "            \n",
    "            print(f\"{param:<12} {pinn_str:<15} {bayes_str:<15} {agree}\")\n",
    "    \n",
    "    print(\"\\nWhen to use each method:\")\n",
    "    print(\"  PINN: Fast (minutes), good for screening\")\n",
    "    print(\"  Bayesian: Rigorous uncertainty, regulatory-grade\")\n",
    "    print(\"  Best: Use both! PINN first, then Bayesian refinement\")\n",
    "else:\n",
    "    print(\"Comparison requires trace (MCMC skipped).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Save and Load Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trace is not None:\n",
    "    # Save trace\n",
    "    bayes.save_trace('bayesian_trace.nc')\n",
    "    print(\"Trace saved to: bayesian_trace.nc\")\n",
    "    \n",
    "    # Load trace\n",
    "    loaded_trace = BayesianEstimator.load_trace('bayesian_trace.nc')\n",
    "    print(\"Trace loaded successfully!\")\n",
    "    \n",
    "    # Verify\n",
    "    loaded_summary = bayes.summarize_posterior(loaded_trace)\n",
    "    print(f\"\\nOriginal g_Na mean: {summary['g_Na']['mean']:.2f}\")\n",
    "    print(f\"Loaded g_Na mean: {loaded_summary['g_Na']['mean']:.2f}\")\n",
    "    print(\"Traces match!\")\n",
    "else:\n",
    "    print(\"Save/load requires trace (MCMC skipped).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated:\n",
    "\n",
    "1. ✅ **Bayesian inference** - Probabilistic parameter estimation\n",
    "2. ✅ **Prior distributions** - Encoding domain knowledge\n",
    "3. ✅ **MCMC sampling** - NUTS algorithm\n",
    "4. ✅ **Posterior analysis** - Mean, SD, credible intervals\n",
    "5. ✅ **Convergence diagnostics** - R-hat, ESS\n",
    "6. ✅ **Visualization** - Trace plots, posterior densities\n",
    "7. ✅ **Comparison with PINN** - Complementary methods\n",
    "8. ✅ **Persistence** - Save/load traces\n",
    "\n",
    "### Key Advantages of Bayesian Inference:\n",
    "\n",
    "- **Full distributions**: Not just point estimates\n",
    "- **Rigorous uncertainty**: 95% credible intervals\n",
    "- **Principled**: Based on probability theory\n",
    "- **Flexible**: Can incorporate expert knowledge (priors)\n",
    "- **Interpretable**: \"95% confident parameter is between X and Y\"\n",
    "\n",
    "### Bayesian vs PINN:\n",
    "\n",
    "| Aspect | Bayesian | PINN |\n",
    "|--------|----------|------|\n",
    "| Speed | Slow (minutes-hours) | Fast (<5 min) |\n",
    "| Uncertainty | Full posterior | Bootstrap CI |\n",
    "| Interpretability | Probabilistic | Point + interval |\n",
    "| Scalability | Limited (10-20 params) | High (100+ params) |\n",
    "| Rigor | Regulatory-grade | Research-grade |\n",
    "\n",
    "### Recommended Workflow:\n",
    "\n",
    "1. **PINN** - Quick screening (~2 minutes)\n",
    "2. **Bayesian** - Refinement with uncertainty (~30 minutes)\n",
    "3. **Clinical decision** - Use Bayesian credible intervals\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try the PINN tutorial (`pinn_tutorial.ipynb`)\n",
    "- Explore clinical workflow (`clinical_workflow.ipynb`)\n",
    "- Test on real patient data\n",
    "- Submit for regulatory approval!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
